"""
Cosmos DB å‘é‡æœå°‹å¯¦ä½œç¯„ä¾‹
2025 å¹´æ¶æ§‹å„ªåŒ– - ä½¿ç”¨åŸç”Ÿå‘é‡ç´¢å¼•æ›¿ä»£ AI Search

å„ªå‹¢:
- å»¶é² < 20ms (vs AI Search ~50-100ms)
- æˆæœ¬æ¯” Pinecone ä½ 43 å€
- çµ±ä¸€è³‡æ–™åº«ï¼ˆç„¡éœ€åˆ†é›¢çš„æœå°‹æœå‹™ï¼‰
- DiskANN æ¼”ç®—æ³•ï¼ˆå¾®è»Ÿç ”ç©¶é™¢é–‹ç™¼ï¼‰
"""

import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from azure.cosmos.aio import CosmosClient
from azure.cosmos import PartitionKey
import structlog

logger = structlog.get_logger()


@dataclass
class VectorSearchResult:
    """å‘é‡æœå°‹çµæœ"""
    id: str
    content: str
    similarity: float
    metadata: Dict[str, Any]


class CosmosVectorStore:
    """
    Cosmos DB å‘é‡å„²å­˜åº« (2025 æ–°åŠŸèƒ½)

    ä½¿ç”¨ DiskANN æ¼”ç®—æ³•å¯¦ç¾é«˜æ•ˆå‘é‡æœå°‹
    """

    def __init__(
        self,
        endpoint: str,
        key: str,
        database_name: str = "call_center_ai",
        container_name: str = "knowledge_base",
        embedding_dimensions: int = 3072  # text-embedding-3-large
    ):
        self.client = CosmosClient(endpoint, key)
        self.database_name = database_name
        self.container_name = container_name
        self.embedding_dimensions = embedding_dimensions

        self.database = None
        self.container = None

    async def initialize(self):
        """åˆå§‹åŒ–è³‡æ–™åº«å’Œå®¹å™¨"""
        logger.info("initializing_cosmos_vector_store")

        # å‰µå»ºæˆ–ç²å–è³‡æ–™åº«
        self.database = await self.client.create_database_if_not_exists(
            id=self.database_name
        )
        logger.info("database_ready", database=self.database_name)

        # å‰µå»ºæˆ–ç²å–å®¹å™¨ï¼ˆå•Ÿç”¨å‘é‡ç´¢å¼•ï¼‰
        await self._create_vector_enabled_container()

        logger.info("cosmos_vector_store_initialized")

    async def _create_vector_enabled_container(self):
        """å‰µå»ºå•Ÿç”¨å‘é‡ç´¢å¼•çš„å®¹å™¨"""

        # å®¹å™¨é…ç½®
        container_config = {
            "id": self.container_name,
            "partition_key": PartitionKey(path="/category"),

            # ğŸ†• å‘é‡ç´¢å¼•ç­–ç•¥ (2025)
            "indexing_policy": {
                "automatic": True,
                "indexing_mode": "consistent",

                # åŒ…å«è·¯å¾‘
                "included_paths": [
                    {"path": "/*"}
                ],

                # å‘é‡ç´¢å¼•
                "vector_indexes": [
                    {
                        "path": "/embedding",
                        "type": "diskANN",  # å¾®è»Ÿ DiskANN æ¼”ç®—æ³•
                        "dimensions": self.embedding_dimensions,
                        "distanceFunction": "cosine",

                        # DiskANN åƒæ•¸
                        "quantization": {
                            "type": "scalar",
                            "bits": 8  # é‡åŒ–ä»¥ç¯€çœå„²å­˜ç©ºé–“
                        }
                    }
                ]
            },

            # å‘é‡åµŒå…¥ç­–ç•¥
            "vector_embedding_policy": {
                "vector_embeddings": [
                    {
                        "path": "/embedding",
                        "dataType": "float32",
                        "dimensions": self.embedding_dimensions,
                        "distanceFunction": "cosine"
                    }
                ]
            }
        }

        # å»ºç«‹å®¹å™¨
        try:
            self.container = await self.database.create_container_if_not_exists(
                **container_config,
                offer_throughput=4000  # è‡ªå‹•æ“´å±• RU
            )
            logger.info(
                "container_created",
                container=self.container_name,
                vector_enabled=True
            )
        except Exception as e:
            logger.error("container_creation_error", error=str(e))
            raise

    async def add_document(
        self,
        doc_id: str,
        content: str,
        embedding: List[float],
        category: str = "general",
        metadata: Dict[str, Any] = None
    ):
        """
        æ·»åŠ æ–‡æª”å’Œå‘é‡

        Args:
            doc_id: æ–‡æª” ID
            content: æ–‡æœ¬å…§å®¹
            embedding: å‘é‡åµŒå…¥ (3072 ç¶­)
            category: åˆ†é¡ (åˆ†å€éµ)
            metadata: å…¶ä»–å…ƒæ•¸æ“š
        """
        document = {
            "id": doc_id,
            "content": content,
            "embedding": embedding,  # å‘é‡æ¬„ä½
            "category": category,
            "metadata": metadata or {},
        }

        try:
            await self.container.create_item(body=document)
            logger.info(
                "document_added",
                doc_id=doc_id,
                category=category,
                embedding_dims=len(embedding)
            )
        except Exception as e:
            logger.error(
                "document_add_error",
                doc_id=doc_id,
                error=str(e)
            )
            raise

    async def vector_search(
        self,
        query_embedding: List[float],
        top_k: int = 5,
        category: Optional[str] = None,
        min_similarity: float = 0.7
    ) -> List[VectorSearchResult]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœå°‹

        Args:
            query_embedding: æŸ¥è©¢å‘é‡
            top_k: è¿”å›å‰ K å€‹çµæœ
            category: å¯é¸çš„åˆ†é¡éæ¿¾
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é–¾å€¼

        Returns:
            æœå°‹çµæœåˆ—è¡¨
        """
        logger.info(
            "vector_search_started",
            top_k=top_k,
            category=category
        )

        # æ§‹å»ºæŸ¥è©¢
        if category:
            # å¸¶åˆ†é¡éæ¿¾çš„æŸ¥è©¢
            query = """
            SELECT TOP @top_k
                c.id,
                c.content,
                c.metadata,
                VectorDistance(c.embedding, @embedding) AS similarity
            FROM c
            WHERE c.category = @category
                AND VectorDistance(c.embedding, @embedding) < @max_distance
            ORDER BY VectorDistance(c.embedding, @embedding)
            """
            parameters = [
                {"name": "@embedding", "value": query_embedding},
                {"name": "@top_k", "value": top_k},
                {"name": "@category", "value": category},
                {"name": "@max_distance", "value": 1 - min_similarity}
            ]
        else:
            # å…¨å±€æœå°‹
            query = """
            SELECT TOP @top_k
                c.id,
                c.content,
                c.metadata,
                VectorDistance(c.embedding, @embedding) AS similarity
            FROM c
            WHERE VectorDistance(c.embedding, @embedding) < @max_distance
            ORDER BY VectorDistance(c.embedding, @embedding)
            """
            parameters = [
                {"name": "@embedding", "value": query_embedding},
                {"name": "@top_k", "value": top_k},
                {"name": "@max_distance", "value": 1 - min_similarity}
            ]

        # åŸ·è¡ŒæŸ¥è©¢
        results = []
        try:
            items = self.container.query_items(
                query=query,
                parameters=parameters,
                enable_cross_partition_query=True
            )

            async for item in items:
                results.append(VectorSearchResult(
                    id=item["id"],
                    content=item["content"],
                    similarity=1 - item["similarity"],  # è½‰æ›ç‚ºç›¸ä¼¼åº¦
                    metadata=item.get("metadata", {})
                ))

            logger.info(
                "vector_search_completed",
                results_count=len(results),
                avg_similarity=sum(r.similarity for r in results) / len(results) if results else 0
            )

        except Exception as e:
            logger.error("vector_search_error", error=str(e))
            raise

        return results

    async def hybrid_search(
        self,
        query_text: str,
        query_embedding: List[float],
        top_k: int = 5,
        text_weight: float = 0.3,
        vector_weight: float = 0.7
    ) -> List[VectorSearchResult]:
        """
        æ··åˆæœå°‹ï¼ˆçµåˆé—œéµå­—å’Œå‘é‡ï¼‰

        Args:
            query_text: æŸ¥è©¢æ–‡æœ¬ï¼ˆç”¨æ–¼é—œéµå­—æœå°‹ï¼‰
            query_embedding: æŸ¥è©¢å‘é‡
            top_k: è¿”å›çµæœæ•¸
            text_weight: æ–‡æœ¬æœå°‹æ¬Šé‡
            vector_weight: å‘é‡æœå°‹æ¬Šé‡

        Returns:
            æ··åˆæœå°‹çµæœ
        """
        query = """
        SELECT TOP @top_k
            c.id,
            c.content,
            c.metadata,
            (
                (@text_weight * RANK(FullTextScore(c.content, [@query_text]))) +
                (@vector_weight * (1 - VectorDistance(c.embedding, @embedding)))
            ) AS hybrid_score
        FROM c
        ORDER BY hybrid_score DESC
        """

        parameters = [
            {"name": "@top_k", "value": top_k},
            {"name": "@query_text", "value": query_text},
            {"name": "@embedding", "value": query_embedding},
            {"name": "@text_weight", "value": text_weight},
            {"name": "@vector_weight", "value": vector_weight}
        ]

        results = []
        try:
            items = self.container.query_items(
                query=query,
                parameters=parameters,
                enable_cross_partition_query=True
            )

            async for item in items:
                results.append(VectorSearchResult(
                    id=item["id"],
                    content=item["content"],
                    similarity=item["hybrid_score"],
                    metadata=item.get("metadata", {})
                ))

            logger.info(
                "hybrid_search_completed",
                results_count=len(results)
            )

        except Exception as e:
            logger.error("hybrid_search_error", error=str(e))
            raise

        return results

    async def close(self):
        """é—œé–‰é€£æ¥"""
        await self.client.close()


class HybridRAGEngine:
    """
    æ··åˆ RAG å¼•æ“
    çµåˆ Redis (ç†±å¿«å–) å’Œ Cosmos DB (å®Œæ•´è³‡æ–™é›†)
    """

    def __init__(
        self,
        cosmos_store: CosmosVectorStore,
        redis_cache: Optional[Any] = None  # RedisVectorCache
    ):
        self.cosmos = cosmos_store
        self.redis = redis_cache

    async def search(
        self,
        query_embedding: List[float],
        top_k: int = 5
    ) -> List[VectorSearchResult]:
        """
        æ™ºèƒ½æœå°‹ç­–ç•¥

        1. å…ˆæŸ¥ Redis (ç†±å¿«å–) - < 5ms
        2. æœªå‘½ä¸­å‰‡æŸ¥ Cosmos DB - < 20ms
        3. è‡ªå‹•æå‡ç†±é–€çµæœåˆ° Redis
        """
        results = []

        # 1. å˜—è©¦ Redis å¿«å–
        if self.redis:
            try:
                cache_results = await self.redis.search(
                    query_embedding,
                    k=top_k
                )
                if cache_results:
                    logger.info("cache_hit", count=len(cache_results))
                    return cache_results
            except Exception as e:
                logger.warning("cache_miss", error=str(e))

        # 2. æŸ¥è©¢ Cosmos DB
        results = await self.cosmos.vector_search(
            query_embedding,
            top_k=top_k
        )

        # 3. æå‡åˆ°ç†±å¿«å–
        if self.redis and results:
            await self._promote_to_cache(results)

        return results

    async def _promote_to_cache(self, results: List[VectorSearchResult]):
        """æå‡çµæœåˆ° Redis å¿«å–"""
        if not self.redis:
            return

        try:
            for result in results:
                await self.redis.add(
                    doc_id=result.id,
                    content=result.content,
                    embedding=result.metadata.get("embedding"),
                    ttl=3600  # 1 å°æ™‚
                )
            logger.info("promoted_to_cache", count=len(results))
        except Exception as e:
            logger.error("cache_promotion_error", error=str(e))


# ä½¿ç”¨ç¯„ä¾‹
async def example_usage():
    """ç¯„ä¾‹ï¼šå¦‚ä½•ä½¿ç”¨ Cosmos DB å‘é‡æœå°‹"""

    # 1. åˆå§‹åŒ–
    store = CosmosVectorStore(
        endpoint="https://your-account.documents.azure.com:443/",
        key="your-key",
        database_name="call_center_ai",
        container_name="knowledge_base"
    )

    await store.initialize()

    # 2. æ·»åŠ æ–‡æª”ï¼ˆé€šå¸¸åœ¨é›¢ç·šè™•ç†ä¸­å®Œæˆï¼‰
    sample_embedding = [0.1] * 3072  # æ¨¡æ“¬ embedding

    await store.add_document(
        doc_id="doc-001",
        content="ä¿éšªç†è³ æµç¨‹ï¼šé¦–å…ˆè¯ç¹«å®¢æœï¼Œæä¾›äº‹æ•…è©³ç´°è³‡è¨Š...",
        embedding=sample_embedding,
        category="insurance_claims",
        metadata={
            "source": "knowledge_base",
            "last_updated": "2025-01-01"
        }
    )

    # 3. å‘é‡æœå°‹
    query_embedding = [0.15] * 3072  # æ¨¡æ“¬æŸ¥è©¢å‘é‡

    results = await store.vector_search(
        query_embedding=query_embedding,
        top_k=5,
        category="insurance_claims",
        min_similarity=0.7
    )

    # 4. è™•ç†çµæœ
    for i, result in enumerate(results, 1):
        print(f"\nçµæœ {i}:")
        print(f"  ç›¸ä¼¼åº¦: {result.similarity:.3f}")
        print(f"  å…§å®¹: {result.content[:100]}...")

    # 5. æ··åˆæœå°‹
    hybrid_results = await store.hybrid_search(
        query_text="å¦‚ä½•ç”³è«‹ç†è³ ",
        query_embedding=query_embedding,
        top_k=5
    )

    # æ¸…ç†
    await store.close()


if __name__ == "__main__":
    asyncio.run(example_usage())
