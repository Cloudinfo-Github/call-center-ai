# ğŸš€ æ¶æ§‹ç¾ä»£åŒ–é·ç§»æŒ‡å—

å¾ç•¶å‰æ¶æ§‹é·ç§»åˆ° 2025 æœ€ä½³å¯¦è¸çš„å®Œæ•´æŒ‡å—ã€‚

---

## ğŸ“‹ é·ç§»å‰æª¢æŸ¥æ¸…å–®

### ç’°å¢ƒæº–å‚™

- [ ] **å‚™ä»½ç•¶å‰ç³»çµ±**
  ```bash
  # å‚™ä»½é…ç½®
  cp config.yaml config.yaml.backup

  # å‚™ä»½è³‡æ–™åº«
  az cosmosdb database backup create \
    --resource-group <your-rg> \
    --account-name <your-account>
  ```

- [ ] **é©—è­‰ Azure è¨‚é–±æ¬Šé™**
  - [ ] æœ‰æ¬Šé™å‰µå»º Cosmos DB å®¹å™¨
  - [ ] æœ‰æ¬Šé™ç®¡ç† Redis
  - [ ] æœ‰æ¬Šé™å­˜å– OpenAI æœå‹™

- [ ] **æº–å‚™æ¸¬è©¦ç’°å¢ƒ**
  - [ ] å»ºç«‹ç¨ç«‹çš„æ¸¬è©¦è³‡æºç¾¤çµ„
  - [ ] æº–å‚™æ¸¬è©¦é›»è©±è™Ÿç¢¼
  - [ ] è¨­å®šç›£æ§å’Œæ—¥èªŒ

- [ ] **æ–‡æª”å’Œæºé€š**
  - [ ] é€šçŸ¥åœ˜éšŠæˆå“¡é·ç§»è¨ˆç•«
  - [ ] æº–å‚™å›æ»¾è¨ˆç•«
  - [ ] è¨­å®šç¶­è­·æ™‚é–“çª—å£

---

## ğŸ¯ é·ç§»éšæ®µ

### **éšæ®µä¸€ï¼šåŸºç¤è¨­æ–½æº–å‚™ï¼ˆç¬¬ 1 é€±ï¼‰**

#### 1.1 å‡ç´šä¾è³´

```bash
# æ›´æ–° pyproject.toml
```

æ–°å¢/æ›´æ–°ä»¥ä¸‹ä¾è³´ï¼š

```toml
[project.dependencies]
openai = ">= 1.60.0"  # æ”¯æ´ Realtime API
orjson = "~= 3.10"    # JSON åŠ é€Ÿ
httpx = "~= 0.28"     # HTTP/2 æ”¯æ´
redis = { version = "~= 5.2", extras = ["hiredis"] }
prometheus-client = "~= 0.21"  # ç›£æ§æŒ‡æ¨™
```

åŸ·è¡Œå®‰è£ï¼š

```bash
uv sync --all-extras
```

#### 1.2 Cosmos DB å‘é‡ç´¢å¼•è¨­å®š

å‰µå»ºé·ç§»è…³æœ¬ï¼š

```python
# scripts/migrate_cosmos_vector.py
import asyncio
from examples.cosmos_vector_search import CosmosVectorStore

async def migrate():
    store = CosmosVectorStore(
        endpoint=os.getenv("COSMOS_ENDPOINT"),
        key=os.getenv("COSMOS_KEY")
    )

    await store.initialize()
    print("âœ… Cosmos DB å‘é‡ç´¢å¼•å·²å•Ÿç”¨")

asyncio.run(migrate())
```

åŸ·è¡Œé·ç§»ï¼š

```bash
python scripts/migrate_cosmos_vector.py
```

#### 1.3 Redis Stack å‡ç´š

å¦‚æœä½¿ç”¨ Azure Cache for Redisï¼š

```bash
# å‡ç´šåˆ° Redis 7.x (æ”¯æ´å‘é‡æœå°‹)
az redis update \
  --resource-group <your-rg> \
  --name <your-redis> \
  --sku Premium \
  --redis-version 7
```

å¦‚æœè‡ªæ¶ Redisï¼š

```bash
docker run -d \
  --name redis-stack \
  -p 6379:6379 \
  redis/redis-stack:latest
```

#### 1.4 OpenAI é…ç½®

åœ¨ Azure OpenAI Studio ä¸­éƒ¨ç½²æ–°æ¨¡å‹ï¼š

```yaml
éƒ¨ç½²æ¸…å–®:
  - gpt-4o-realtime-preview (2024-12-17)
  - gpt-4o-transcribe
  - o3-mini (2025-01-31)
```

---

### **éšæ®µäºŒï¼šç¨‹å¼ç¢¼é‡æ§‹ï¼ˆç¬¬ 2-3 é€±ï¼‰**

#### 2.1 å‰µå»ºæ–°æ¨¡çµ„çµæ§‹

```bash
mkdir -p app/core/{voice,llm,rag,optimization}
mkdir -p app/services/{azure,openai,cache}
```

#### 2.2 æ•´åˆ Realtime API

è¤‡è£½ç¯„ä¾‹åˆ°å°ˆæ¡ˆï¼š

```bash
cp examples/realtime_api_integration.py app/core/voice/realtime.py
```

ä¿®æ”¹æ•´åˆåˆ°ç¾æœ‰ç³»çµ±ï¼š

```python
# app/core/voice/realtime.py
from app.helpers.llm_tools import DefaultPlugin

class RealtimeVoiceAgent:
    def __init__(self, config, plugin: DefaultPlugin):
        self.plugin = plugin
        # ... å…¶ä»–åˆå§‹åŒ–

    async def _execute_tool(self, function_name, arguments):
        """æ•´åˆç¾æœ‰å·¥å…·ç³»çµ±"""
        return await getattr(self.plugin, function_name)(**arguments)
```

#### 2.3 å¯¦æ–½æ™ºèƒ½è·¯ç”±

å‰µå»ºè·¯ç”±é‚è¼¯ï¼š

```python
# app/core/voice/router.py
from typing import Literal

RouteStrategy = Literal["realtime", "traditional", "smart"]

class VoiceRouter:
    def __init__(
        self,
        realtime_handler,
        traditional_handler,
        strategy: RouteStrategy = "smart"
    ):
        self.realtime = realtime_handler
        self.traditional = traditional_handler
        self.strategy = strategy

    async def route_call(self, call_context):
        if self.strategy == "smart":
            # æ™ºèƒ½é¸æ“‡
            if call_context.requires_low_latency:
                return await self.realtime.handle(call_context)
            else:
                return await self.traditional.handle(call_context)

        elif self.strategy == "realtime":
            return await self.realtime.handle(call_context)

        else:
            return await self.traditional.handle(call_context)
```

#### 2.4 æ•´åˆ Cosmos DB å‘é‡æœå°‹

```bash
cp examples/cosmos_vector_search.py app/persistence/cosmos_vector.py
```

æ›´æ–° RAG ç®¡é“ï¼š

```python
# app/helpers/call_llm.py ä¸­çš„ RAG æ•´åˆ

from app.persistence.cosmos_vector import CosmosVectorStore, HybridRAGEngine

# æ›¿æ›ç¾æœ‰çš„ AI Search
rag_engine = HybridRAGEngine(
    cosmos_store=cosmos_vector_store,
    redis_cache=redis_vector_cache
)

# åœ¨ LLM è™•ç†å‰æŸ¥è©¢
async def get_context(query):
    embedding = await get_embedding(query)
    results = await rag_engine.search(embedding, top_k=5)
    return [r.content for r in results]
```

---

### **éšæ®µä¸‰ï¼šA/B æ¸¬è©¦éƒ¨ç½²ï¼ˆç¬¬ 4 é€±ï¼‰**

#### 3.1 å¯¦æ–½ A/B æ¸¬è©¦æ¡†æ¶

```python
# app/core/experiments/ab_test.py
import hashlib

class ABTest:
    def __init__(self, test_name: str, variants: dict):
        self.test_name = test_name
        self.variants = variants  # {"A": 0.5, "B": 0.5}

    def get_variant(self, user_id: str) -> str:
        """æ ¹æ“š user_id ç©©å®šåˆ†é…è®Šé«”"""
        hash_value = int(
            hashlib.md5(f"{self.test_name}:{user_id}".encode()).hexdigest(),
            16
        )
        ratio = (hash_value % 100) / 100

        cumulative = 0
        for variant, weight in self.variants.items():
            cumulative += weight
            if ratio < cumulative:
                return variant

        return list(self.variants.keys())[0]

# ä½¿ç”¨
ab_test = ABTest(
    test_name="realtime_vs_traditional",
    variants={"realtime": 0.3, "traditional": 0.7}
)

variant = ab_test.get_variant(call_id)
if variant == "realtime":
    handler = realtime_handler
else:
    handler = traditional_handler
```

#### 3.2 é…ç½®ç›£æ§

```python
# app/core/monitoring/metrics.py
from prometheus_client import Histogram, Counter, Gauge

# å»¶é²æŒ‡æ¨™
latency_histogram = Histogram(
    'call_latency_seconds',
    'Call latency distribution',
    ['variant', 'stage']
)

# æˆæœ¬æŒ‡æ¨™
cost_gauge = Gauge(
    'call_cost_dollars',
    'Cost per call',
    ['variant']
)

# å“è³ªæŒ‡æ¨™
completion_rate = Gauge(
    'call_completion_rate',
    'Successful completion rate',
    ['variant']
)
```

#### 3.3 é€æ­¥æ¨å»£

```yaml
# Week 1: 30% Realtime
variants:
  realtime: 0.3
  traditional: 0.7

# Week 2: 50% Realtime (å¦‚æœæŒ‡æ¨™è‰¯å¥½)
variants:
  realtime: 0.5
  traditional: 0.5

# Week 3: 70% Realtime
variants:
  realtime: 0.7
  traditional: 0.3

# Week 4: 100% Realtime
variants:
  realtime: 1.0
```

---

### **éšæ®µå››ï¼šå„ªåŒ–å’Œç©©å®šï¼ˆç¬¬ 5-6 é€±ï¼‰**

#### 4.1 æ•ˆèƒ½èª¿å„ª

**è³‡æ–™åº«é€£æ¥æ± å„ªåŒ–ï¼š**

```python
# app/persistence/cosmos_db.py
from azure.cosmos.aio import CosmosClient

client = CosmosClient(
    url=config.endpoint,
    credential=config.key,
    connection_pool_size=20,  # å¢åŠ é€£æ¥æ± 
    connection_timeout=30,
    request_timeout=10
)
```

**Redis é€£æ¥æ± å„ªåŒ–ï¼š**

```python
# app/persistence/redis.py
import redis.asyncio as redis

pool = redis.ConnectionPool(
    host=config.host,
    port=config.port,
    max_connections=50,  # å¢åŠ æœ€å¤§é€£æ¥æ•¸
    socket_timeout=5,
    socket_keepalive=True,
    decode_responses=True
)
```

**FastAPI å„ªåŒ–ï¼š**

```python
# app/main.py
from fastapi import FastAPI
from fastapi.responses import ORJSONResponse

app = FastAPI(
    default_response_class=ORJSONResponse,  # ä½¿ç”¨ orjson
    docs_url="/docs" if config.env == "dev" else None
)

# æ·»åŠ ä¸­ä»‹è»Ÿé«”
@app.middleware("http")
async def add_process_time_header(request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = str(process_time)
    return response
```

#### 4.2 å¿«å–ç­–ç•¥å„ªåŒ–

```python
# app/helpers/cache.py
from functools import wraps
import hashlib

def cache_embeddings(ttl=3600):
    """å¿«å– embedding çµæœ"""
    def decorator(func):
        @wraps(func)
        async def wrapper(text: str, *args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            cache_key = f"emb:{hashlib.md5(text.encode()).hexdigest()}"

            # æŸ¥è©¢å¿«å–
            cached = await redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # è¨ˆç®—ä¸¦å¿«å–
            result = await func(text, *args, **kwargs)
            await redis_client.setex(
                cache_key,
                ttl,
                json.dumps(result)
            )
            return result
        return wrapper
    return decorator

@cache_embeddings(ttl=86400)  # å¿«å– 24 å°æ™‚
async def get_embedding(text: str):
    # ... OpenAI API èª¿ç”¨
    pass
```

---

## ğŸ§ª æ¸¬è©¦è¨ˆç•«

### å–®å…ƒæ¸¬è©¦

```python
# tests/test_realtime_integration.py
import pytest
from app.core.voice.realtime import RealtimeVoiceAgent

@pytest.mark.asyncio
async def test_realtime_session():
    agent = RealtimeVoiceAgent(
        api_key="test-key",
        model="gpt-4o-realtime-preview"
    )

    async def mock_audio_stream():
        yield b'\x00' * 1024

    events = []
    async for event in agent.start_session(mock_audio_stream()):
        events.append(event)

    assert len(events) > 0
```

### æ•´åˆæ¸¬è©¦

```python
# tests/test_cosmos_vector.py
import pytest
from app.persistence.cosmos_vector import CosmosVectorStore

@pytest.mark.asyncio
async def test_vector_search():
    store = CosmosVectorStore(
        endpoint=os.getenv("TEST_COSMOS_ENDPOINT"),
        key=os.getenv("TEST_COSMOS_KEY")
    )

    await store.initialize()

    # æ·»åŠ æ¸¬è©¦æ–‡æª”
    await store.add_document(
        doc_id="test-001",
        content="æ¸¬è©¦å…§å®¹",
        embedding=[0.1] * 3072,
        category="test"
    )

    # æœå°‹
    results = await store.vector_search(
        query_embedding=[0.1] * 3072,
        top_k=1
    )

    assert len(results) == 1
    assert results[0].id == "test-001"
```

### è² è¼‰æ¸¬è©¦

```python
# tests/load_test.py
from locust import HttpUser, task, between

class CallCenterUser(HttpUser):
    wait_time = between(1, 3)

    @task
    def initiate_call(self):
        self.client.post("/call", json={
            "phone_number": "+1234567890",
            "initiate": {
                "bot_name": "Test Bot"
            }
        })

    @task(3)
    def get_call_status(self):
        self.client.get("/call")
```

åŸ·è¡Œè² è¼‰æ¸¬è©¦ï¼š

```bash
locust -f tests/load_test.py --host http://localhost:8080
```

---

## ğŸ“Š ç›£æ§å’Œé©—è­‰

### é—œéµæŒ‡æ¨™

å»ºç«‹ç›£æ§å„€è¡¨æ¿è¿½è¹¤ä»¥ä¸‹æŒ‡æ¨™ï¼š

| æŒ‡æ¨™ | ç›®æ¨™ | å‘Šè­¦é–¾å€¼ |
|------|------|----------|
| P50 å»¶é² | < 250ms | > 400ms |
| P95 å»¶é² | < 400ms | > 600ms |
| P99 å»¶é² | < 600ms | > 1000ms |
| å®Œæˆç‡ | > 95% | < 90% |
| éŒ¯èª¤ç‡ | < 0.1% | > 1% |
| æˆæœ¬/é€šè©± | < $0.15 | > $0.25 |

### Application Insights æŸ¥è©¢

```kusto
// å»¶é²åˆ†ä½ˆ
customMetrics
| where name == "call_latency_seconds"
| extend variant = tostring(customDimensions.variant)
| summarize
    p50=percentile(value, 50),
    p95=percentile(value, 95),
    p99=percentile(value, 99)
    by variant
| render timechart

// æˆæœ¬æ¯”è¼ƒ
customMetrics
| where name == "call_cost_dollars"
| extend variant = tostring(customDimensions.variant)
| summarize avg_cost=avg(value) by variant
| render columnchart

// éŒ¯èª¤ç‡
requests
| where success == false
| extend variant = tostring(customDimensions.variant)
| summarize error_rate=count() by variant, bin(timestamp, 1h)
| render timechart
```

---

## ğŸ”„ å›æ»¾è¨ˆç•«

å¦‚æœé·ç§»é‡åˆ°å•é¡Œï¼ŒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿå›æ»¾ï¼š

### 1. åˆ‡æ›å›å‚³çµ±æ¶æ§‹

```python
# config.yaml
voice:
  routing:
    strategy: traditional  # å¼·åˆ¶ä½¿ç”¨å‚³çµ±ç®¡é“
```

### 2. æ¢å¾©é…ç½®

```bash
cp config.yaml.backup config.yaml
```

### 3. é‡æ–°éƒ¨ç½²

```bash
make deploy name=<your-resource-group>
```

### 4. é©—è­‰

```bash
# åŸ·è¡Œå¥åº·æª¢æŸ¥
curl http://your-app/health/readiness

# æª¢æŸ¥æ—¥èªŒ
make logs name=<your-resource-group>
```

---

## âœ… é·ç§»å®Œæˆæª¢æŸ¥æ¸…å–®

- [ ] **æ•ˆèƒ½é©—è­‰**
  - [ ] P50 å»¶é² < 250ms
  - [ ] P95 å»¶é² < 400ms
  - [ ] P99 å»¶é² < 600ms

- [ ] **æˆæœ¬é©—è­‰**
  - [ ] æ¯é€šé›»è©±æˆæœ¬ < $0.15
  - [ ] æœˆåº¦ç¸½æˆæœ¬é™ä½

- [ ] **å“è³ªé©—è­‰**
  - [ ] å®Œæˆç‡ > 95%
  - [ ] è½‰æ¥ç‡ < 5%
  - [ ] éŒ¯èª¤ç‡ < 0.1%

- [ ] **æ–‡æª”æ›´æ–°**
  - [ ] æ›´æ–° README.md
  - [ ] æ›´æ–°éƒ¨ç½²æ–‡æª”
  - [ ] æ›´æ–°é‹ç¶­æ‰‹å†Š

- [ ] **åœ˜éšŠåŸ¹è¨“**
  - [ ] é–‹ç™¼åœ˜éšŠäº†è§£æ–°æ¶æ§‹
  - [ ] é‹ç¶­åœ˜éšŠäº†è§£ç›£æ§æŒ‡æ¨™
  - [ ] æº–å‚™æ•…éšœæ’é™¤æŒ‡å—

- [ ] **æ¸…ç†**
  - [ ] ç§»é™¤èˆŠçš„ AI Search è³‡æº
  - [ ] æ¸…ç†æ¸¬è©¦è³‡æº
  - [ ] æ­¸æª”å‚™ä»½

---

## ğŸ†˜ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. Realtime API é€£æ¥å¤±æ•—

```python
# éŒ¯èª¤: WebSocket connection failed
# è§£æ±ºæ–¹æ¡ˆ: æª¢æŸ¥ç¶²è·¯é…ç½®å’Œé˜²ç«ç‰†è¦å‰‡

# é©—è­‰é€£æ¥
import websockets

async def test_connection():
    async with websockets.connect(
        "wss://api.openai.com/v1/realtime",
        extra_headers={"Authorization": f"Bearer {api_key}"}
    ) as ws:
        print("é€£æ¥æˆåŠŸ")
```

#### 2. Cosmos DB å‘é‡ç´¢å¼•æœªç”Ÿæ•ˆ

```bash
# æª¢æŸ¥å®¹å™¨é…ç½®
az cosmosdb sql container show \
  --resource-group <rg> \
  --account-name <account> \
  --database-name call_center_ai \
  --name knowledge_base \
  --query 'resource.vectorEmbeddingPolicy'
```

#### 3. Redis è¨˜æ†¶é«”ä¸è¶³

```bash
# æª¢æŸ¥ Redis è¨˜æ†¶é«”ä½¿ç”¨
redis-cli INFO memory

# èª¿æ•´æ·˜æ±°ç­–ç•¥
redis-cli CONFIG SET maxmemory-policy allkeys-lru
```

---

## ğŸ“ æ”¯æ´

å¦‚é‡å•é¡Œï¼Œè«‹ï¼š

1. æŸ¥çœ‹ [GitHub Issues](https://github.com/microsoft/call-center-ai/issues)
2. è¯ç¹«åœ˜éšŠæ”¯æ´
3. åƒè€ƒ Azure æ–‡æª”

---

**ç¥é·ç§»é †åˆ©ï¼ğŸš€**
